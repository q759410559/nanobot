#!/bin/bash
# è‡ªåŠ¨åº”ç”¨ longcat provider æ”¯æŒè¡¥ä¸

set -e

PROJECT_ROOT="$(cd "$(dirname "$0")/.." && pwd)"

echo "ğŸ”§ åº”ç”¨ longcat provider æ”¯æŒè¡¥ä¸..."

# 1. è¡¥ä¸ litellm_provider.py
echo "ğŸ“ è¡¥ä¸ nanobot/providers/litellm_provider.py..."
LITELLM_FILE="$PROJECT_ROOT/nanobot/providers/litellm_provider.py"

# æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å« longcat
if ! grep -q "is_longcat" "$LITELLM_FILE"; then
    # åœ¨ __init__ æ–¹æ³•ä¸­æ·»åŠ  longcat æ£€æµ‹
    sed -i '/self.is_openrouter = (/a\
\
        # Detect Longcat by api_base\
        self.is_longcat = bool(api_base) and "longcat" in api_base.lower()' "$LITELLM_FILE"

    # æ›´æ–° is_vllm æ£€æµ‹ï¼Œæ’é™¤ longcat
    sed -i 's/self.is_vllm = bool(api_base) and not self.is_openrouter/self.is_vllm = bool(api_base) and not self.is_openrouter and not self.is_longcat/' "$LITELLM_FILE"

    # åœ¨ OpenAI client åˆ›å»ºæ¡ä»¶ä¸­æ·»åŠ  longcat
    sed -i 's/if self.is_vllm:/if self.is_longcat or self.is_vllm:/' "$LITELLM_FILE"

    # åœ¨ chat æ–¹æ³•ä¸­æ·»åŠ  longcat æ¨¡å‹å¤„ç†
    sed -i '/# For vLLM, use hosted_vllm\/ prefix per LiteLLM docs/a\
\
        # For longcat, remove any provider prefix and use raw model name\
        if self.is_longcat:\
            # Remove openai\/ prefix if present\
            if model.startswith("openai\/"):\
                model = model[7:]' "$LITELLM_FILE"

    # åœ¨ OpenAI client æ³¨é‡Šä¸­æ·»åŠ  longcat
    sed -i 's/OpenAI-compatible endpoints (vLLM)/OpenAI-compatible endpoints (longcat, vLLM)/' "$LITELLM_FILE"

    echo "âœ… litellm_provider.py è¡¥ä¸å·²åº”ç”¨"
else
    echo "â­ï¸  litellm_provider.py å·²åŒ…å« longcat æ”¯æŒï¼Œè·³è¿‡"
fi

# 2. è¡¥ä¸ schema.py
echo "ğŸ“ è¡¥ä¸ nanobot/config/schema.py..."
SCHEMA_FILE="$PROJECT_ROOT/nanobot/config/schema.py"

# æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å« longcat
if ! grep -q "longcat.*ProviderConfig" "$SCHEMA_FILE"; then
    # åœ¨ ProvidersConfig ç±»ä¸­æ·»åŠ  longcat
    sed -i '/self.providers.gemini = Field(default_factory=ProviderConfig)/a\        longcat: ProviderConfig = Field(default_factory=ProviderConfig)' "$SCHEMA_FILE"

    # åœ¨ providers å­—å…¸ä¸­æ·»åŠ  longcat æ˜ å°„
    sed -i '/"vllm": self.providers.vllm,/a\            "longcat": self.providers.longcat,' "$SCHEMA_FILE"

    # åœ¨ get_api_key æ–¹æ³•ä¸­æ·»åŠ  longcat
    sed -i '/self.providers.groq,/a\            self.providers.longcat,' "$SCHEMA_FILE"

    # åœ¨ get_api_base æ–¹æ³•ä¸­æ·»åŠ  longcat
    sed -i '/if "moonshot"/i\        if "longcat" in model:\
            return self.providers.longcat.api_base\
' "$SCHEMA_FILE"

    echo "âœ… schema.py è¡¥ä¸å·²åº”ç”¨"
else
    echo "â­ï¸  schema.py å·²åŒ…å« longcat æ”¯æŒï¼Œè·³è¿‡"
fi

# 3. è¡¥ä¸ README.md
echo "ğŸ“ è¡¥ä¸ README.md..."
README_FILE="$PROJECT_ROOT/README.md"

# æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å« longcat
if ! grep -q "longcat" "$README_FILE"; then
    # åœ¨ providers è¡¨æ ¼ä¸­æ·»åŠ  longcat
    sed -i '/| `gemini` | LLM (Gemini direct) | \[aistudio.google.com\]/a| `longcat` | LLM (LongCat - è‡ªå®šä¹‰ API) | https://api.longcat.chat/openai |' "$README_FILE"

    echo "âœ… README.md è¡¥ä¸å·²åº”ç”¨"
else
    echo "â­ï¸  README.md å·²åŒ…å« longcat æ”¯æŒï¼Œè·³è¿‡"
fi

echo ""
echo "ğŸ‰ æ‰€æœ‰è¡¥ä¸å·²æˆåŠŸåº”ç”¨ï¼"
echo ""
echo "ğŸ“Œ æç¤ºï¼šconfig.json åœ¨ .gitignore ä¸­ï¼Œä½ çš„ longcat é…ç½®ä¸ä¼šè¢«è·Ÿè¸ªã€‚"
echo "ğŸ“Œ æç¤ºï¼šä¸‹æ¬¡ä»ä¸Šæ¸¸æ›´æ–°åï¼Œå†æ¬¡è¿è¡Œæ­¤è„šæœ¬å³å¯é‡æ–°åº”ç”¨è¡¥ä¸ã€‚"
